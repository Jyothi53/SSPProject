{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4042447,"sourceType":"datasetVersion","datasetId":2394508}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport re\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport librosa\nimport librosa.display\nfrom sklearn.preprocessing import minmax_scale\nimport IPython.display as ipd\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:21:58.999099Z","iopub.execute_input":"2025-04-03T15:21:58.999555Z","iopub.status.idle":"2025-04-03T15:22:00.028775Z","shell.execute_reply.started":"2025-04-03T15:21:58.999510Z","shell.execute_reply":"2025-04-03T15:22:00.027832Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dysarthria-detection/torgo_data/data.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:22:02.710717Z","iopub.execute_input":"2025-04-03T15:22:02.711007Z","iopub.status.idle":"2025-04-03T15:22:02.730575Z","shell.execute_reply.started":"2025-04-03T15:22:02.710987Z","shell.execute_reply":"2025-04-03T15:22:02.729623Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"       is_dysarthria  gender  \\\n0     non_dysarthria  female   \n1     non_dysarthria  female   \n2     non_dysarthria  female   \n3     non_dysarthria  female   \n4     non_dysarthria  female   \n...              ...     ...   \n1995      dysarthria    male   \n1996      dysarthria    male   \n1997      dysarthria    male   \n1998      dysarthria    male   \n1999      dysarthria    male   \n\n                                               filename  \n0     torgo_data/non_dysarthria_female/FC03_Session2...  \n1     torgo_data/non_dysarthria_female/FC02_Session3...  \n2     torgo_data/non_dysarthria_female/FC02_Session3...  \n3     torgo_data/non_dysarthria_female/FC03_Session2...  \n4     torgo_data/non_dysarthria_female/FC03_Session1...  \n...                                                 ...  \n1995   torgo_data/dysarthria_male/M03_Session2_0144.wav  \n1996   torgo_data/dysarthria_male/M02_Session1_0005.wav  \n1997   torgo_data/dysarthria_male/M03_Session2_0040.wav  \n1998   torgo_data/dysarthria_male/M03_Session2_0260.wav  \n1999   torgo_data/dysarthria_male/M03_Session2_0145.wav  \n\n[2000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_dysarthria</th>\n      <th>gender</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>non_dysarthria</td>\n      <td>female</td>\n      <td>torgo_data/non_dysarthria_female/FC03_Session2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>non_dysarthria</td>\n      <td>female</td>\n      <td>torgo_data/non_dysarthria_female/FC02_Session3...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>non_dysarthria</td>\n      <td>female</td>\n      <td>torgo_data/non_dysarthria_female/FC02_Session3...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>non_dysarthria</td>\n      <td>female</td>\n      <td>torgo_data/non_dysarthria_female/FC03_Session2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>non_dysarthria</td>\n      <td>female</td>\n      <td>torgo_data/non_dysarthria_female/FC03_Session1...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>dysarthria</td>\n      <td>male</td>\n      <td>torgo_data/dysarthria_male/M03_Session2_0144.wav</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>dysarthria</td>\n      <td>male</td>\n      <td>torgo_data/dysarthria_male/M02_Session1_0005.wav</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>dysarthria</td>\n      <td>male</td>\n      <td>torgo_data/dysarthria_male/M03_Session2_0040.wav</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>dysarthria</td>\n      <td>male</td>\n      <td>torgo_data/dysarthria_male/M03_Session2_0260.wav</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>dysarthria</td>\n      <td>male</td>\n      <td>torgo_data/dysarthria_male/M03_Session2_0145.wav</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df['filename'] = df['filename'].apply(lambda x: os.path.join('/kaggle/input/dysarthria-detection',x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:22:05.373102Z","iopub.execute_input":"2025-04-03T15:22:05.373419Z","iopub.status.idle":"2025-04-03T15:22:05.381762Z","shell.execute_reply.started":"2025-04-03T15:22:05.373393Z","shell.execute_reply":"2025-04-03T15:22:05.380523Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def extract_mfcc_features(signal, fs, n_mfcc=52):\n    preemphasized_signal = librosa.effects.preemphasis(signal)\n    mfccs = librosa.feature.mfcc(y=preemphasized_signal, sr=fs, n_mfcc=n_mfcc)\n    return np.mean(mfccs, axis=1)\n\n\ndef feature_extraction_only_mfcc(df):\n    features = []\n    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n        try:\n            speech, fs = librosa.load(record['filename'])\n            mfcc_features = extract_mfcc_features(speech, fs)  # (52 features)\n            all_features = np.concatenate([mfcc_features])\n            features.append(np.append(all_features, [record['is_dysarthria'], record['gender']]))  \n        except Exception as e:\n            print(f\"Error processing {record['filename']}: {e}\")\n\n    column_names = (\n        [f\"MFCC_{i}\" for i in range(52)] + ['class', 'gender'])\n    return pd.DataFrame(features, columns=column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:22:05.711298Z","iopub.execute_input":"2025-04-03T15:22:05.711781Z","iopub.status.idle":"2025-04-03T15:22:05.721079Z","shell.execute_reply.started":"2025-04-03T15:22:05.711742Z","shell.execute_reply":"2025-04-03T15:22:05.719977Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_with_feat_mfcc = feature_extraction_only_mfcc(df)\ndata_with_feat_mfcc['class'] = data_with_feat_mfcc['class'].replace('non_dysarthria',0)\ndata_with_feat_mfcc['class'] = data_with_feat_mfcc['class'].replace('dysarthria',1)\ndata_with_feat_mfcc['gender'] = data_with_feat_mfcc['gender'].replace('male', 1)\ndata_with_feat_mfcc['gender'] = data_with_feat_mfcc['gender'].replace('female', 0)\ndata_with_feat_mfcc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:22:06.974715Z","iopub.execute_input":"2025-04-03T15:22:06.975001Z","iopub.status.idle":"2025-04-03T15:22:45.328187Z","shell.execute_reply.started":"2025-04-03T15:22:06.974982Z","shell.execute_reply":"2025-04-03T15:22:45.327043Z"}},"outputs":[{"name":"stderr","text":" 30%|██▉       | 599/2000 [00:11<00:23, 60.47it/s]<ipython-input-4-791cab90e331>:11: UserWarning: PySoundFile failed. Trying audioread instead.\n  speech, fs = librosa.load(record['filename'])\n/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n 30%|███       | 607/2000 [00:11<00:21, 64.31it/s]","output_type":"stream"},{"name":"stdout","text":"Error processing /kaggle/input/dysarthria-detection/torgo_data/dysarthria_female/F01_Session1_0068.wav: \n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 1554/2000 [00:29<00:08, 50.93it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=209\n  warnings.warn(\n 78%|███████▊  | 1567/2000 [00:29<00:07, 54.89it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=583\n  warnings.warn(\n 80%|███████▉  | 1599/2000 [00:30<00:07, 51.84it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=581\n  warnings.warn(\n 83%|████████▎ | 1668/2000 [00:31<00:05, 56.52it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=185\n  warnings.warn(\n 85%|████████▍ | 1699/2000 [00:32<00:05, 54.97it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=946\n  warnings.warn(\n 92%|█████████▏| 1835/2000 [00:34<00:03, 51.61it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=214\n  warnings.warn(\n100%|██████████| 2000/2000 [00:38<00:00, 52.28it/s]\n<ipython-input-5-5df5e0e70326>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_mfcc['class'] = data_with_feat_mfcc['class'].replace('dysarthria',1)\n<ipython-input-5-5df5e0e70326>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_mfcc['gender'] = data_with_feat_mfcc['gender'].replace('female', 0)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"          MFCC_0     MFCC_1      MFCC_2     MFCC_3      MFCC_4     MFCC_5  \\\n0      -319.7045  35.161507   -66.34302  51.268147  -50.792416   34.19954   \n1     -395.44254  40.966072   -64.21012   49.29909  -52.021427   34.75533   \n2      -400.7094  45.508183   -73.22846  57.570812   -59.73956  40.009903   \n3     -303.36227  42.922634   -77.73571   44.11482   -58.83759  34.619595   \n4      -380.4776  41.505455  -70.097115  60.845333  -55.586807   44.16475   \n...          ...        ...         ...        ...         ...        ...   \n1994   -402.0437   48.89409   -49.44366   37.44017  -35.224632  23.513338   \n1995  -567.24225   53.42506  -24.851572   5.648115  -42.638477  14.371315   \n1996  -472.70474  55.216194  -48.241093  38.618504   -31.28108  22.451336   \n1997   -406.1352  54.426342  -61.200016  50.883335   -42.66797  20.043901   \n1998  -487.27414  36.031265   -47.23318   49.10351   -46.44953  33.414024   \n\n          MFCC_6     MFCC_7       MFCC_8        MFCC_9  ...      MFCC_44  \\\n0      -29.19774  17.997763   -9.4621935    -0.5122181  ...   -4.5058756   \n1      -20.61536  25.536705   -7.5747924     4.6627607  ...    -6.344143   \n2     -23.322557  26.447178    -7.871122     5.9670362  ...   -7.1083784   \n3      -27.90659  18.597755  -10.9610815     4.2977843  ...    -6.555074   \n4     -29.470608  26.530014    -8.528628     3.3341653  ...   -6.7447896   \n...          ...        ...          ...           ...  ...          ...   \n1994  -17.929684   8.643148    -9.682321     -4.864476  ...   -1.2102699   \n1995  -28.034782  12.563507   -5.3071346    -2.4107144  ...  -0.19318683   \n1996  -14.904069  16.969027    -5.566646     1.9870967  ...   -3.0755556   \n1997  -20.154718    17.3035   -13.471844    -4.6676664  ...   -0.9948297   \n1998  -17.258854  20.593779   -7.8412533  -0.040905878  ...    -2.008442   \n\n          MFCC_45      MFCC_46     MFCC_47     MFCC_48       MFCC_49  \\\n0      -1.5363845   -5.0564704  -3.4387124  -4.2227654    -2.2731867   \n1       -4.169222   -6.5706644  -2.3804123  -3.0671916    -2.7551515   \n2       -3.794058    -6.653496   -3.121459  -4.4126153    -2.3347008   \n3      -1.2236726   -3.9311428  -1.7308125    -1.85476    -2.1504872   \n4       -2.504473   -7.4847293  -1.6244006  -3.1706736     -2.378174   \n...           ...          ...         ...         ...           ...   \n1994    0.2593692  -0.30640313   4.1314764   4.4224787     2.0771952   \n1995    5.2797875    2.5829372   5.5325646   2.6679924     0.4258839   \n1996  -0.32984915    -2.210794    3.444888   2.3652935      2.474335   \n1997    2.6853592     1.079636   2.7016742   1.9857001      3.738986   \n1998   0.44578946   -3.0101967   3.1765375   1.9096487  -0.044238985   \n\n          MFCC_50      MFCC_51 class gender  \n0       0.4243103  -0.49626946     0      0  \n1      0.38413244   -0.8819986     0      0  \n2     -0.13959113   -0.8432585     0      0  \n3      0.38307458   -1.4279135     0      0  \n4       0.8780274  0.091998786     0      0  \n...           ...          ...   ...    ...  \n1994     3.580518     4.074891     1      1  \n1995    1.1258968   0.17784452     1      1  \n1996    5.7890086    3.5479848     1      1  \n1997    3.9398618    2.0509567     1      1  \n1998    2.3231723     2.810866     1      1  \n\n[1999 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MFCC_0</th>\n      <th>MFCC_1</th>\n      <th>MFCC_2</th>\n      <th>MFCC_3</th>\n      <th>MFCC_4</th>\n      <th>MFCC_5</th>\n      <th>MFCC_6</th>\n      <th>MFCC_7</th>\n      <th>MFCC_8</th>\n      <th>MFCC_9</th>\n      <th>...</th>\n      <th>MFCC_44</th>\n      <th>MFCC_45</th>\n      <th>MFCC_46</th>\n      <th>MFCC_47</th>\n      <th>MFCC_48</th>\n      <th>MFCC_49</th>\n      <th>MFCC_50</th>\n      <th>MFCC_51</th>\n      <th>class</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-319.7045</td>\n      <td>35.161507</td>\n      <td>-66.34302</td>\n      <td>51.268147</td>\n      <td>-50.792416</td>\n      <td>34.19954</td>\n      <td>-29.19774</td>\n      <td>17.997763</td>\n      <td>-9.4621935</td>\n      <td>-0.5122181</td>\n      <td>...</td>\n      <td>-4.5058756</td>\n      <td>-1.5363845</td>\n      <td>-5.0564704</td>\n      <td>-3.4387124</td>\n      <td>-4.2227654</td>\n      <td>-2.2731867</td>\n      <td>0.4243103</td>\n      <td>-0.49626946</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-395.44254</td>\n      <td>40.966072</td>\n      <td>-64.21012</td>\n      <td>49.29909</td>\n      <td>-52.021427</td>\n      <td>34.75533</td>\n      <td>-20.61536</td>\n      <td>25.536705</td>\n      <td>-7.5747924</td>\n      <td>4.6627607</td>\n      <td>...</td>\n      <td>-6.344143</td>\n      <td>-4.169222</td>\n      <td>-6.5706644</td>\n      <td>-2.3804123</td>\n      <td>-3.0671916</td>\n      <td>-2.7551515</td>\n      <td>0.38413244</td>\n      <td>-0.8819986</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-400.7094</td>\n      <td>45.508183</td>\n      <td>-73.22846</td>\n      <td>57.570812</td>\n      <td>-59.73956</td>\n      <td>40.009903</td>\n      <td>-23.322557</td>\n      <td>26.447178</td>\n      <td>-7.871122</td>\n      <td>5.9670362</td>\n      <td>...</td>\n      <td>-7.1083784</td>\n      <td>-3.794058</td>\n      <td>-6.653496</td>\n      <td>-3.121459</td>\n      <td>-4.4126153</td>\n      <td>-2.3347008</td>\n      <td>-0.13959113</td>\n      <td>-0.8432585</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-303.36227</td>\n      <td>42.922634</td>\n      <td>-77.73571</td>\n      <td>44.11482</td>\n      <td>-58.83759</td>\n      <td>34.619595</td>\n      <td>-27.90659</td>\n      <td>18.597755</td>\n      <td>-10.9610815</td>\n      <td>4.2977843</td>\n      <td>...</td>\n      <td>-6.555074</td>\n      <td>-1.2236726</td>\n      <td>-3.9311428</td>\n      <td>-1.7308125</td>\n      <td>-1.85476</td>\n      <td>-2.1504872</td>\n      <td>0.38307458</td>\n      <td>-1.4279135</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-380.4776</td>\n      <td>41.505455</td>\n      <td>-70.097115</td>\n      <td>60.845333</td>\n      <td>-55.586807</td>\n      <td>44.16475</td>\n      <td>-29.470608</td>\n      <td>26.530014</td>\n      <td>-8.528628</td>\n      <td>3.3341653</td>\n      <td>...</td>\n      <td>-6.7447896</td>\n      <td>-2.504473</td>\n      <td>-7.4847293</td>\n      <td>-1.6244006</td>\n      <td>-3.1706736</td>\n      <td>-2.378174</td>\n      <td>0.8780274</td>\n      <td>0.091998786</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>-402.0437</td>\n      <td>48.89409</td>\n      <td>-49.44366</td>\n      <td>37.44017</td>\n      <td>-35.224632</td>\n      <td>23.513338</td>\n      <td>-17.929684</td>\n      <td>8.643148</td>\n      <td>-9.682321</td>\n      <td>-4.864476</td>\n      <td>...</td>\n      <td>-1.2102699</td>\n      <td>0.2593692</td>\n      <td>-0.30640313</td>\n      <td>4.1314764</td>\n      <td>4.4224787</td>\n      <td>2.0771952</td>\n      <td>3.580518</td>\n      <td>4.074891</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>-567.24225</td>\n      <td>53.42506</td>\n      <td>-24.851572</td>\n      <td>5.648115</td>\n      <td>-42.638477</td>\n      <td>14.371315</td>\n      <td>-28.034782</td>\n      <td>12.563507</td>\n      <td>-5.3071346</td>\n      <td>-2.4107144</td>\n      <td>...</td>\n      <td>-0.19318683</td>\n      <td>5.2797875</td>\n      <td>2.5829372</td>\n      <td>5.5325646</td>\n      <td>2.6679924</td>\n      <td>0.4258839</td>\n      <td>1.1258968</td>\n      <td>0.17784452</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>-472.70474</td>\n      <td>55.216194</td>\n      <td>-48.241093</td>\n      <td>38.618504</td>\n      <td>-31.28108</td>\n      <td>22.451336</td>\n      <td>-14.904069</td>\n      <td>16.969027</td>\n      <td>-5.566646</td>\n      <td>1.9870967</td>\n      <td>...</td>\n      <td>-3.0755556</td>\n      <td>-0.32984915</td>\n      <td>-2.210794</td>\n      <td>3.444888</td>\n      <td>2.3652935</td>\n      <td>2.474335</td>\n      <td>5.7890086</td>\n      <td>3.5479848</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>-406.1352</td>\n      <td>54.426342</td>\n      <td>-61.200016</td>\n      <td>50.883335</td>\n      <td>-42.66797</td>\n      <td>20.043901</td>\n      <td>-20.154718</td>\n      <td>17.3035</td>\n      <td>-13.471844</td>\n      <td>-4.6676664</td>\n      <td>...</td>\n      <td>-0.9948297</td>\n      <td>2.6853592</td>\n      <td>1.079636</td>\n      <td>2.7016742</td>\n      <td>1.9857001</td>\n      <td>3.738986</td>\n      <td>3.9398618</td>\n      <td>2.0509567</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>-487.27414</td>\n      <td>36.031265</td>\n      <td>-47.23318</td>\n      <td>49.10351</td>\n      <td>-46.44953</td>\n      <td>33.414024</td>\n      <td>-17.258854</td>\n      <td>20.593779</td>\n      <td>-7.8412533</td>\n      <td>-0.040905878</td>\n      <td>...</td>\n      <td>-2.008442</td>\n      <td>0.44578946</td>\n      <td>-3.0101967</td>\n      <td>3.1765375</td>\n      <td>1.9096487</td>\n      <td>-0.044238985</td>\n      <td>2.3231723</td>\n      <td>2.810866</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1999 rows × 54 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"X_mfcc = data_with_feat_mfcc.drop(columns = ['class'])\nX_mfcc.columns = X_mfcc.columns.astype(str)\ny_mfcc = data_with_feat_mfcc['class']\nX_mfcc = X_mfcc.astype(float)\n\nX_train_mfcc, X_test_mfcc, y_train_mfcc, y_test_mfcc = train_test_split(X_mfcc, y_mfcc, test_size=0.2, stratify=y_mfcc, random_state = 42)\n\n# to handle with NaN, Inf, or constant features\nX_train_mfcc.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_train_mfcc.fillna(X_train_mfcc.mean(), inplace=True)\nX_train_mfcc = X_train_mfcc.loc[:, X_train_mfcc.nunique() > 1] \nX_train_mfcc = X_train_mfcc.astype(float)\ny_train_mfcc = y_train_mfcc.astype(int)\n\nscaler = StandardScaler()\nX_train_mfcc = scaler.fit_transform(X_train_mfcc)\nX_test_mfcc = scaler.transform(X_test_mfcc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:23:41.078329Z","iopub.execute_input":"2025-04-03T15:23:41.078635Z","iopub.status.idle":"2025-04-03T15:23:41.281891Z","shell.execute_reply.started":"2025-04-03T15:23:41.078587Z","shell.execute_reply":"2025-04-03T15:23:41.280790Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid=[\n    {'C':[0.5,1,10,100, 1000],\n     'gamma':[10,1,0.1,0.001,0.00001, 0.000001],\n     'kernel':['rbf'],\n    }\n]\n\noptional_params=GridSearchCV(SVC(),param_grid,cv=5,scoring='accuracy',verbose=0)\noptional_params.fit(X_train_mfcc,y_train_mfcc)\nprint(\"Best parameters for original dataset:\")\nprint(optional_params.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:23:41.623679Z","iopub.execute_input":"2025-04-03T15:23:41.624201Z","iopub.status.idle":"2025-04-03T15:24:02.554458Z","shell.execute_reply.started":"2025-04-03T15:23:41.624154Z","shell.execute_reply":"2025-04-03T15:24:02.553529Z"}},"outputs":[{"name":"stdout","text":"Best parameters for original dataset:\n{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model_mfcc = SVC(kernel='rbf', gamma=0.1, C=10)\nmodel_mfcc.fit(X_train_mfcc, y_train_mfcc)\n\nfrom sklearn.metrics import accuracy_score\npredictions = model_mfcc.predict(X_test_mfcc) \nprint(100*accuracy_score(y_test_mfcc, predictions), \"% accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:24:15.853066Z","iopub.execute_input":"2025-04-03T15:24:15.853386Z","iopub.status.idle":"2025-04-03T15:24:16.054738Z","shell.execute_reply.started":"2025-04-03T15:24:15.853360Z","shell.execute_reply":"2025-04-03T15:24:16.053989Z"}},"outputs":[{"name":"stdout","text":"98.25 % accuracy\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Only Mel RCC (LPC-residual)","metadata":{}},{"cell_type":"markdown","source":"https://www.researchgate.net/publication/272912634_Feature_Extraction_Using_LPC-Residual_and_MelFrequency_Cepstral_Coefficients_in_Forensic_Speaker_Recognition","metadata":{}},{"cell_type":"code","source":"from scipy import signal\ndef lp_residual(signal_data, order=10):\n    preemphasized_signal = librosa.effects.preemphasis(signal_data)\n    a = librosa.lpc(preemphasized_signal, order=order)\n    residual = signal.lfilter([1] + -1 * a[1:].tolist(), [1], preemphasized_signal)\n    return residual\n\ndef extract_rcc_features(signal_data, fs, n_rcc=52):\n    residual = lp_residual(signal_data)\n    # hilbert_transformed = np.abs(signal.hilbert(residual))\n    rccs = librosa.feature.mfcc(y=residual, sr=fs, n_mfcc=n_rcc)\n    return np.mean(rccs, axis=1)\n    \n\ndef feature_extraction_only_rcc(df):\n    features = []\n    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n        try:\n            speech, fs = librosa.load(record['filename'])\n            rcc_features = extract_rcc_features(speech, fs)  # (52 features)\n            all_features = np.concatenate([rcc_features])\n            features.append(np.append(all_features, [record['is_dysarthria'], record['gender']]))  \n        except Exception as e:\n            print(f\"Error processing {record['filename']}: {e}\")\n    \n    column_names = (\n        [f\"RCC_{i}\" for i in range(52)] + ['class', 'gender'])\n    return pd.DataFrame(features, columns=column_names)\n\ndata_with_feat_rcc = feature_extraction_only_rcc(df)\ndata_with_feat_rcc['class'] = data_with_feat_rcc['class'].replace('non_dysarthria', 0)\ndata_with_feat_rcc['class'] = data_with_feat_rcc['class'].replace('dysarthria', 1)\ndata_with_feat_rcc['gender'] = data_with_feat_rcc['gender'].replace('male', 1)\ndata_with_feat_rcc['gender'] = data_with_feat_rcc['gender'].replace('female', 0)\n\nX_rcc = data_with_feat_rcc.drop(columns=['class'])\nX_rcc.columns = X_rcc.columns.astype(str)\ny_rcc = data_with_feat_rcc['class']\nX_rcc = X_rcc.astype(float)\n\nX_train_rcc, X_test_rcc, y_train_rcc, y_test_rcc = train_test_split(X_rcc, y_rcc, test_size=0.2, stratify=y_rcc, random_state=42)\n\nX_train_rcc.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_train_rcc.fillna(X_train_rcc.mean(), inplace=True)\nX_train_rcc = X_train_rcc.loc[:, X_train_rcc.nunique() > 1] \nX_train_rcc = X_train_rcc.astype(float)\ny_train_rcc = y_train_rcc.astype(int)\n\n\n# scaler = StandardScaler()\n# X_train_rcc = scaler.fit_transform(X_train_rcc)\n# X_test_rcc = scaler.transform(X_test_rcc)\n\nparam_grid = [\n    {'C': [0.5, 1, 10, 100, 1000],\n     'gamma': [10, 1, 0.1, 0.001, 0.00001, 0.000001],\n     'kernel': ['rbf'],\n    }\n]\n\noptional_params = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=0)\noptional_params.fit(X_train_rcc, y_train_rcc)\nprint(\"Best parameters for original dataset:\")\nprint(optional_params.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:24:20.169146Z","iopub.execute_input":"2025-04-03T15:24:20.169442Z","iopub.status.idle":"2025-04-03T15:25:19.336866Z","shell.execute_reply.started":"2025-04-03T15:24:20.169419Z","shell.execute_reply":"2025-04-03T15:25:19.335970Z"}},"outputs":[{"name":"stderr","text":" 30%|██▉       | 597/2000 [00:11<00:30, 46.64it/s]<ipython-input-13-9b59b4de6376>:19: UserWarning: PySoundFile failed. Trying audioread instead.\n  speech, fs = librosa.load(record['filename'])\n/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n 30%|███       | 609/2000 [00:11<00:29, 47.71it/s]","output_type":"stream"},{"name":"stdout","text":"Error processing /kaggle/input/dysarthria-detection/torgo_data/dysarthria_female/F01_Session1_0068.wav: \n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 1554/2000 [00:29<00:10, 41.67it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=209\n  warnings.warn(\n 78%|███████▊  | 1566/2000 [00:29<00:08, 49.00it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=583\n  warnings.warn(\n 80%|███████▉  | 1597/2000 [00:29<00:08, 49.15it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=581\n  warnings.warn(\n 83%|████████▎ | 1668/2000 [00:31<00:07, 45.72it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=185\n  warnings.warn(\n 85%|████████▌ | 1700/2000 [00:32<00:06, 46.52it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=946\n  warnings.warn(\n 92%|█████████▏| 1839/2000 [00:35<00:03, 41.31it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=214\n  warnings.warn(\n100%|██████████| 2000/2000 [00:39<00:00, 50.89it/s]\n<ipython-input-13-9b59b4de6376>:32: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_rcc['class'] = data_with_feat_rcc['class'].replace('dysarthria', 1)\n<ipython-input-13-9b59b4de6376>:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_rcc['gender'] = data_with_feat_rcc['gender'].replace('female', 0)\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for original dataset:\n{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"model_rcc = SVC(kernel='rbf', gamma=1e-3, C=100)\nmodel_rcc.fit(X_train_rcc, y_train_rcc)\n\nfrom sklearn.metrics import accuracy_score\npredictions = model_rcc.predict(X_test_rcc)\nprint(100 * accuracy_score(y_test_rcc, predictions), \"% accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:30:47.714065Z","iopub.execute_input":"2025-04-03T15:30:47.714348Z","iopub.status.idle":"2025-04-03T15:30:47.823719Z","shell.execute_reply.started":"2025-04-03T15:30:47.714327Z","shell.execute_reply":"2025-04-03T15:30:47.822798Z"}},"outputs":[{"name":"stdout","text":"98.5 % accuracy\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# MFCC+Mel RCC (52+52)","metadata":{}},{"cell_type":"code","source":"from scipy import signal\ndef lp_residual(signal_data, order=10):\n    preemphasized_signal = librosa.effects.preemphasis(signal_data)\n    a = librosa.lpc(preemphasized_signal, order=order)\n    residual = signal.lfilter([1] + -1 * a[1:].tolist(), [1], preemphasized_signal)\n    return residual\n\ndef extract_mfcc_rcc_features(signal_data, fs, n_mfcc=52, n_rcc=52):\n    preemphasized_signal = librosa.effects.preemphasis(signal_data)\n    mfccs = librosa.feature.mfcc(y=preemphasized_signal, sr=fs, n_mfcc=n_mfcc)\n    residual = lp_residual(signal_data)\n    # hilbert_transformed = np.abs(signal.hilbert(residual))\n    rccs = librosa.feature.mfcc(y=residual, sr=fs, n_mfcc=n_rcc)\n    return np.concatenate([np.mean(mfccs, axis=1), np.mean(rccs, axis=1)])\n\ndef feature_extraction_mfcc_rcc(df, n_mfcc=52, n_rcc=52):\n    features = []\n    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n        try:\n            speech, fs = librosa.load(record['filename'])\n            combined_features = extract_mfcc_rcc_features(speech, fs, n_mfcc, n_rcc)\n            features.append(np.append(combined_features, [record['is_dysarthria'], record['gender']]))  \n        except Exception as e:\n            print(f\"Error processing {record['filename']}: {e}\")\n    \n    column_names = (\n        [f\"MFCC_{i}\" for i in range(n_mfcc)] + [f\"RCC_{i}\" for i in range(n_rcc)] + ['class', 'gender'])\n    return pd.DataFrame(features, columns=column_names)\n\ndata_with_feat_mfcc_rcc = feature_extraction_mfcc_rcc(df, n_mfcc=52, n_rcc=52)\ndata_with_feat_mfcc_rcc['class'] = data_with_feat_mfcc_rcc['class'].replace('non_dysarthria', 0)\ndata_with_feat_mfcc_rcc['class'] = data_with_feat_mfcc_rcc['class'].replace('dysarthria', 1)\ndata_with_feat_mfcc_rcc['gender'] = data_with_feat_mfcc_rcc['gender'].replace('male', 1)\ndata_with_feat_mfcc_rcc['gender'] = data_with_feat_mfcc_rcc['gender'].replace('female', 0)\n\nX_mfcc_rcc = data_with_feat_mfcc_rcc.drop(columns=['class'])\nX_mfcc_rcc.columns = X_mfcc_rcc.columns.astype(str)\ny_mfcc_rcc = data_with_feat_mfcc_rcc['class']\nX_mfcc_rcc = X_mfcc_rcc.astype(float)\n\nX_train_mfcc_rcc, X_test_mfcc_rcc, y_train_mfcc_rcc, y_test_mfcc_rcc = train_test_split(X_mfcc_rcc, y_mfcc_rcc, test_size=0.2, stratify=y_mfcc_rcc, random_state=42)\n\nX_train_mfcc_rcc.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_train_mfcc_rcc.fillna(X_train_mfcc_rcc.mean(), inplace=True)\nX_train_mfcc_rcc = X_train_mfcc_rcc.loc[:, X_train_mfcc_rcc.nunique() > 1] \nX_train_mfcc_rcc = X_train_mfcc_rcc.astype(float)\ny_train_mfcc_rcc = y_train_mfcc_rcc.astype(int)\n\n# scaler = StandardScaler()\n# X_train_mfcc_rcc = scaler.fit_transform(X_train_mfcc_rcc)\n# X_test_mfcc_rcc = scaler.transform(X_test_mfcc_rcc)\n\n\nparam_grid = [\n    {'C': [0.5, 1, 10, 100, 1000],\n     'gamma': [10, 1, 0.1, 0.001, 0.00001, 0.000001],\n     'kernel': ['rbf'],\n    }\n]\n\noptional_params = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=0)\noptional_params.fit(X_train_mfcc_rcc, y_train_mfcc_rcc)\nprint(\"Best parameters for original dataset:\")\nprint(optional_params.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:25:19.448878Z","iopub.execute_input":"2025-04-03T15:25:19.449161Z","iopub.status.idle":"2025-04-03T15:26:39.072975Z","shell.execute_reply.started":"2025-04-03T15:25:19.449140Z","shell.execute_reply":"2025-04-03T15:26:39.072036Z"}},"outputs":[{"name":"stderr","text":" 30%|██▉       | 598/2000 [00:15<00:40, 35.00it/s]<ipython-input-15-42e72c829fb2>:20: UserWarning: PySoundFile failed. Trying audioread instead.\n  speech, fs = librosa.load(record['filename'])\n/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n 30%|███       | 607/2000 [00:15<00:40, 34.14it/s]","output_type":"stream"},{"name":"stdout","text":"Error processing /kaggle/input/dysarthria-detection/torgo_data/dysarthria_female/F01_Session1_0068.wav: \n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 1551/2000 [00:39<00:13, 32.14it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=209\n  warnings.warn(\n 78%|███████▊  | 1565/2000 [00:39<00:12, 35.89it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=583\n  warnings.warn(\n 80%|███████▉  | 1598/2000 [00:40<00:11, 33.91it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=581\n  warnings.warn(\n 83%|████████▎ | 1669/2000 [00:43<00:09, 35.32it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=185\n  warnings.warn(\n 85%|████████▌ | 1702/2000 [00:44<00:08, 33.41it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=946\n  warnings.warn(\n 92%|█████████▏| 1837/2000 [00:48<00:05, 30.21it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=214\n  warnings.warn(\n100%|██████████| 2000/2000 [00:53<00:00, 37.37it/s]\n<ipython-input-15-42e72c829fb2>:32: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_mfcc_rcc['class'] = data_with_feat_mfcc_rcc['class'].replace('dysarthria', 1)\n<ipython-input-15-42e72c829fb2>:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_mfcc_rcc['gender'] = data_with_feat_mfcc_rcc['gender'].replace('female', 0)\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for original dataset:\n{'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model_mfcc_rcc = SVC(kernel='rbf', gamma=1e-5, C=1000)\nmodel_mfcc_rcc.fit(X_train_mfcc_rcc, y_train_mfcc_rcc)\n\npredictions = model_mfcc_rcc.predict(X_test_mfcc_rcc)\nprint(100 * accuracy_score(y_test_mfcc_rcc, predictions), \"% accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:26:39.074137Z","iopub.execute_input":"2025-04-03T15:26:39.074405Z","iopub.status.idle":"2025-04-03T15:26:39.183212Z","shell.execute_reply.started":"2025-04-03T15:26:39.074384Z","shell.execute_reply":"2025-04-03T15:26:39.182267Z"}},"outputs":[{"name":"stdout","text":"98.25 % accuracy\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Linear RCCs\nReference: https://dl.acm.org/doi/10.1007/978-3-031-78498-9_22","metadata":{}},{"cell_type":"code","source":"from scipy.fftpack import dct\n\ndef lp_residual(signal_data, order=10):\n    preemphasized_signal = librosa.effects.preemphasis(signal_data)\n    a = librosa.lpc(preemphasized_signal, order=order)\n    residual = signal.lfilter([1] + -1 * a[1:].tolist(), [1], preemphasized_signal)\n    return residual\n\ndef extract_linear_lrcc(signal_data, fs, n_lrcc=52, n_filters=52):\n    residual = lp_residual(signal_data)\n    spectrum = np.abs(np.fft.rfft(residual))\n    freqs = np.linspace(0, fs / 2, n_filters + 2)  # Linear spaced frequencies\n    bins = np.floor((len(spectrum) - 1) * freqs / (fs / 2)).astype(int)\n    \n    filterbank = np.zeros((n_filters, len(spectrum)))\n    for i in range(1, n_filters + 1):\n        filterbank[i - 1, bins[i - 1]: bins[i]] = np.linspace(0, 1, bins[i] - bins[i - 1])\n        filterbank[i - 1, bins[i]: bins[i + 1]] = np.linspace(1, 0, bins[i + 1] - bins[i])  \n    filtered_spectrum = np.dot(filterbank, spectrum[:len(spectrum)])\n    log_spectrum = np.log1p(filtered_spectrum)\n    lrccs = dct(log_spectrum, type=2, norm='ortho')[:n_lrcc]\n    \n    return lrccs\n\ndef feature_extraction_only_lrcc(df):\n    features = []\n    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n        try:\n            speech, fs = librosa.load(record['filename'])\n            lrcc_features = extract_linear_lrcc(speech, fs)  # Extract linear lrccs\n            all_features = np.concatenate([lrcc_features])\n            features.append(np.append(all_features, [record['is_dysarthria'], record['gender']]))  \n        except Exception as e:\n            print(f\"Error processing {record['filename']}: {e}\")\n    \n    column_names = [f\"lrcc_{i}\" for i in range(52)] + ['class', 'gender']\n    return pd.DataFrame(features, columns=column_names)\n\ndata_with_feat_lrcc = feature_extraction_only_lrcc(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:26:39.184144Z","iopub.execute_input":"2025-04-03T15:26:39.184455Z","iopub.status.idle":"2025-04-03T15:27:22.750539Z","shell.execute_reply.started":"2025-04-03T15:26:39.184430Z","shell.execute_reply":"2025-04-03T15:27:22.749717Z"}},"outputs":[{"name":"stderr","text":" 30%|██▉       | 597/2000 [00:12<00:32, 43.23it/s]<ipython-input-17-2eab24ba9f43>:29: UserWarning: PySoundFile failed. Trying audioread instead.\n  speech, fs = librosa.load(record['filename'])\n/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n 31%|███       | 611/2000 [00:12<00:26, 51.65it/s]","output_type":"stream"},{"name":"stdout","text":"Error processing /kaggle/input/dysarthria-detection/torgo_data/dysarthria_female/F01_Session1_0068.wav: \n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:43<00:00, 45.97it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"data_with_feat_lrcc['class'] = data_with_feat_lrcc['class'].replace('non_dysarthria', 0)\ndata_with_feat_lrcc['class'] = data_with_feat_lrcc['class'].replace('dysarthria', 1)\ndata_with_feat_lrcc['gender'] = data_with_feat_lrcc['gender'].replace('male', 1)\ndata_with_feat_lrcc['gender'] = data_with_feat_lrcc['gender'].replace('female', 0)\n\nX_lrcc = data_with_feat_lrcc.drop(columns=['class'])\nX_lrcc.columns = X_lrcc.columns.astype(str)\ny_lrcc = data_with_feat_lrcc['class']\nX_lrcc = X_lrcc.astype(float)\n\nX_train_lrcc, X_test_lrcc, y_train_lrcc, y_test_lrcc = train_test_split(X_lrcc, y_lrcc, test_size=0.2, stratify=y_lrcc, random_state=42)\n\nX_train_lrcc.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_train_lrcc.fillna(X_train_lrcc.mean(), inplace=True)\nX_train_lrcc = X_train_lrcc.loc[:, X_train_lrcc.nunique() > 1] \nX_train_lrcc = X_train_lrcc.astype(float)\ny_train_lrcc = y_train_lrcc.astype(int)\n\n# scaler = StandardScaler()\n# X_train_lrcc = scaler.fit_transform(X_train_lrcc)\n# X_test_lrcc = scaler.transform(X_test_lrcc)\n\n\nparam_grid = [\n    {'C': [0.5, 1, 10, 100, 1000],\n     'gamma': [10, 1, 0.1, 0.001, 0.00001, 0.000001],\n     'kernel': ['rbf'],\n    }\n]\n\noptional_params = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=0)\noptional_params.fit(X_train_lrcc, y_train_lrcc)\nprint(\"Best parameters for original dataset:\")\nprint(optional_params.best_params_)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:27:22.751404Z","iopub.execute_input":"2025-04-03T15:27:22.751728Z","iopub.status.idle":"2025-04-03T15:27:47.118628Z","shell.execute_reply.started":"2025-04-03T15:27:22.751704Z","shell.execute_reply":"2025-04-03T15:27:47.117716Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-81f690dc58a7>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_lrcc['class'] = data_with_feat_lrcc['class'].replace('dysarthria', 1)\n<ipython-input-18-81f690dc58a7>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_lrcc['gender'] = data_with_feat_lrcc['gender'].replace('female', 0)\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for original dataset:\n{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model_lrcc = SVC(kernel='rbf', gamma=0.001, C=1000)\nmodel_lrcc.fit(X_train_lrcc, y_train_lrcc)\n\nfrom sklearn.metrics import accuracy_score\npredictions = model_lrcc.predict(X_test_lrcc)\nprint(100 * accuracy_score(y_test_lrcc, predictions), \"% accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:30:25.732143Z","iopub.execute_input":"2025-04-03T15:30:25.732435Z","iopub.status.idle":"2025-04-03T15:30:26.051086Z","shell.execute_reply.started":"2025-04-03T15:30:25.732414Z","shell.execute_reply":"2025-04-03T15:30:26.050190Z"}},"outputs":[{"name":"stdout","text":"87.25 % accuracy\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"### Why Mel RCCs perform better than linear RCCs\n\n**Mel Scaling Captures Speech Better** - Speech perception is logarithmic, and the Mel scale emphasizes lower frequencies, which are more crucial for speech intelligibility.\n\n**Better Feature Separation** - In dysarthria detection, the lower formants and excitation signals are crucial, and Mel filtering may enhance this.","metadata":{}},{"cell_type":"markdown","source":"\n# Linear RCC + MFCC","metadata":{}},{"cell_type":"code","source":"def feature_extraction_mfcc_lrcc(df, n_mfcc=52, n_lrcc=52):\n    features = []\n    for i, record in tqdm(df.iterrows(), total=df.shape[0]):\n        try:\n            speech, fs = librosa.load(record['filename'])\n            lrcc_features = extract_linear_lrcc(speech, fs,  n_lrcc=n_lrcc, n_filters=n_lrcc)  \n            preemphasized_signal = librosa.effects.preemphasis(speech)\n            mfccs = librosa.feature.mfcc(y=preemphasized_signal, sr=fs, n_mfcc=n_mfcc)\n            combined_features = np.concatenate([np.mean(mfccs, axis=1), lrcc_features])\n            features.append(np.append(combined_features, [record['is_dysarthria'], record['gender']]))  \n        except Exception as e:\n            print(f\"Error processing {record['filename']}: {e}\")\n    \n    column_names = (\n        [f\"MFCC_{i}\" for i in range(n_mfcc)] + [f\"lrcc_{i}\" for i in range(n_lrcc)] + ['class', 'gender'])\n    return pd.DataFrame(features, columns=column_names)\n\ndata_with_feat_mfcc_lrcc = feature_extraction_mfcc_lrcc(df, n_mfcc=52, n_lrcc=52)\ndata_with_feat_mfcc_lrcc['class'] = data_with_feat_mfcc_lrcc['class'].replace('non_dysarthria', 0)\ndata_with_feat_mfcc_lrcc['class'] = data_with_feat_mfcc_lrcc['class'].replace('dysarthria', 1)\ndata_with_feat_mfcc_lrcc['gender'] = data_with_feat_mfcc_lrcc['gender'].replace('male', 1)\ndata_with_feat_mfcc_lrcc['gender'] = data_with_feat_mfcc_lrcc['gender'].replace('female', 0)\n\nX_mfcc_lrcc = data_with_feat_mfcc_lrcc.drop(columns=['class'])\nX_mfcc_lrcc.columns = X_mfcc_lrcc.columns.astype(str)\ny_mfcc_lrcc = data_with_feat_mfcc_lrcc['class']\nX_mfcc_lrcc = X_mfcc_lrcc.astype(float)\n\nX_train_mfcc_lrcc, X_test_mfcc_lrcc, y_train_mfcc_lrcc, y_test_mfcc_lrcc = train_test_split(X_mfcc_lrcc, y_mfcc_lrcc, test_size=0.2, stratify=y_mfcc_lrcc, random_state=42)\n\nX_train_mfcc_lrcc.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_train_mfcc_lrcc.fillna(X_train_mfcc_lrcc.mean(), inplace=True)\nX_train_mfcc_lrcc = X_train_mfcc_lrcc.loc[:, X_train_mfcc_lrcc.nunique() > 1] \nX_train_mfcc_lrcc = X_train_mfcc_lrcc.astype(float)\ny_train_mfcc_lrcc = y_train_mfcc_lrcc.astype(int)\n\n# scaler = StandardScaler()\n# X_train_mfcc_lrcc = scaler.fit_transform(X_train_mfcc_lrcc)\n# X_test_mfcc_lrcc = scaler.transform(X_test_mfcc_lrcc)\n\n\n\nparam_grid = [\n    {'C': [0.5, 1, 10, 100, 1000],\n     'gamma': [10, 1, 0.1, 0.001, 0.00001, 0.000001],\n     'kernel': ['rbf'],\n    }\n]\n\noptional_params = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=0)\noptional_params.fit(X_train_mfcc_lrcc, y_train_mfcc_lrcc)\nprint(\"Best parameters for original dataset:\")\nprint(optional_params.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:27:47.317762Z","iopub.execute_input":"2025-04-03T15:27:47.318034Z","iopub.status.idle":"2025-04-03T15:29:12.462331Z","shell.execute_reply.started":"2025-04-03T15:27:47.318014Z","shell.execute_reply":"2025-04-03T15:29:12.461349Z"}},"outputs":[{"name":"stderr","text":" 30%|███       | 600/2000 [00:16<00:43, 32.48it/s]<ipython-input-20-750661723217>:5: UserWarning: PySoundFile failed. Trying audioread instead.\n  speech, fs = librosa.load(record['filename'])\n/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n 30%|███       | 605/2000 [00:17<00:38, 36.12it/s]","output_type":"stream"},{"name":"stdout","text":"Error processing /kaggle/input/dysarthria-detection/torgo_data/dysarthria_female/F01_Session1_0068.wav: \n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 1554/2000 [00:43<00:15, 29.31it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=209\n  warnings.warn(\n 78%|███████▊  | 1567/2000 [00:43<00:12, 34.34it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=583\n  warnings.warn(\n 80%|███████▉  | 1598/2000 [00:44<00:13, 29.58it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=581\n  warnings.warn(\n 84%|████████▎ | 1671/2000 [00:47<00:11, 29.77it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=185\n  warnings.warn(\n 85%|████████▌ | 1700/2000 [00:48<00:10, 27.51it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=946\n  warnings.warn(\n 92%|█████████▏| 1840/2000 [00:53<00:06, 26.41it/s]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=214\n  warnings.warn(\n100%|██████████| 2000/2000 [00:59<00:00, 33.49it/s]\n<ipython-input-20-750661723217>:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_mfcc_lrcc['class'] = data_with_feat_mfcc_lrcc['class'].replace('dysarthria', 1)\n<ipython-input-20-750661723217>:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data_with_feat_mfcc_lrcc['gender'] = data_with_feat_mfcc_lrcc['gender'].replace('female', 0)\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for original dataset:\n{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model_mfcc_lrcc = SVC(kernel='rbf', gamma=0.001, C=100)\nmodel_mfcc_lrcc.fit(X_train_mfcc_lrcc, y_train_mfcc_lrcc)\n\npredictions = model_mfcc_lrcc.predict(X_test_mfcc_lrcc)\nprint(100 * accuracy_score(y_test_mfcc_lrcc, predictions), \"% accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:30:00.584792Z","iopub.execute_input":"2025-04-03T15:30:00.585083Z","iopub.status.idle":"2025-04-03T15:30:00.734555Z","shell.execute_reply.started":"2025-04-03T15:30:00.585063Z","shell.execute_reply":"2025-04-03T15:30:00.733719Z"}},"outputs":[{"name":"stdout","text":"98.5 % accuracy\n","output_type":"stream"}],"execution_count":22}]}